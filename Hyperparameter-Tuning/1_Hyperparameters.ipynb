{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d5f437",
   "metadata": {},
   "source": [
    "Elements of models that cannot be learned by fitting the model.  \n",
    "\n",
    "Common Examples:\n",
    "- Alpha in Ridge/Lasso Regression\n",
    "- n_neighbors in k-NN\n",
    "- a and b in Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781052b9",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a5943",
   "metadata": {},
   "source": [
    "- Learned from data, include split-point in node, split-features, etc.\n",
    "- Another way to put it: components of the model **learned during the modeling process**\n",
    "- **you do not set these**; the algorithm sets these and will disover these for the user.\n",
    "\n",
    "Where to Find Parameters:\n",
    "- Know about the algorithm first and foremost\n",
    "- But also located in the Scikit Learn documentation - **under \"Attributes\" section**\n",
    "    - NOT in the \"parameters\" section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef4372",
   "metadata": {},
   "source": [
    "Linear Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73743e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example in linear regression the coefficients of each data point\n",
    "#for viewing\n",
    "\n",
    "original_variables = list(X_train.columns)\n",
    "\n",
    "#zip together names and coefficients\n",
    "zipped_together = list(zip(original_variables, log_reg_clf.coef_[0]))\n",
    "coefs = [list(x) for x in zipped_together]\n",
    "\n",
    "#put into DataFrame with column labels\n",
    "coefs = pd.DataFrame(coefs, columns = [\"Variable\", \"Coefficient\"])\n",
    "\n",
    "#sort dataframe and print top three coeffiencients\n",
    "coefs.sort_values(by=[\"Coefficient\"], axis=0, inplace=True, ascending=False)\n",
    "print(coefs.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another example\n",
    "# Create a list of original variable names from the training DataFrame\n",
    "original_variables = X_train.columns\n",
    "\n",
    "# Extract the coefficients of the logistic regression estimator\n",
    "model_coefficients = log_reg_clf.coef_[0]\n",
    "\n",
    "# Create a dataframe of the variables and coefficients & print it out\n",
    "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \n",
    "                               \"Coefficient\": model_coefficients})\n",
    "print(coefficient_df)\n",
    "\n",
    "# Print out the top 3 positive variables\n",
    "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, \n",
    "                                          ascending=False)[0:3]\n",
    "print(top_three_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f005d",
   "metadata": {},
   "source": [
    "Parameters in Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194dee7",
   "metadata": {},
   "source": [
    "- the parameters are in the **node decisions** to build the model (what feature and what value to split on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75794a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the node decisions\n",
    "\n",
    "#get the columns it split on\n",
    "split_column = chosen_tree.tree_.feature[1]\n",
    "split_column_name = X_train.columns[split_column]\n",
    "\n",
    "#get the level it split on\n",
    "split_value = chosen_tree.tree_.threshold[1]\n",
    "\n",
    "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3280ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 2\n",
    "# Extract the 7th (index 6) tree from the random forest\n",
    "chosen_tree = rf_clf.estimators_[6]\n",
    "\n",
    "# Visualize the graph using the provided image\n",
    "imgplot = plt.imshow(tree_viz_image)\n",
    "plt.show()\n",
    "\n",
    "# Extract the parameters and level of the top (index 0) node\n",
    "split_column = chosen_tree.tree_.feature[0]\n",
    "split_column_name = X_train.columns[split_column]\n",
    "split_value = chosen_tree.tree_.threshold[0]\n",
    "\n",
    "# Print out the feature and level\n",
    "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82ad69",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d629a",
   "metadata": {},
   "source": [
    "- Not learned from data, set prior to training, include max_depth, min_sample_leaf, splitting criterion, etc.\n",
    "- **something that is set BEFORE the modeling process begins**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcf04d",
   "metadata": {},
   "source": [
    "##### Hyperparameters that matter:\n",
    "\n",
    "Random Forest:\n",
    "- **n_estimators** (pref. and not uncommon to have a high value)\n",
    "- **max_features** (try different values to ensure tree diversity)\n",
    "- **max_depth, min_sample_leaf** (important for overfitting)\n",
    "- **criterion** (maybe)\n",
    "\n",
    "Sources for learning about hyperparameters:\n",
    "- Academic papers\n",
    "- Scikit Learn module documentation\n",
    "- Practical experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff77fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all the knobs and dials to set for a model\n",
    "#example\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "print(rf_clf)\n",
    "\n",
    "#for what they mean: http://scikit-learn.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5e67c",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning\n",
    "- trying and experimenting with hyperparameter values and choosing the ones that perform the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7bf88",
   "metadata": {},
   "source": [
    "Even with hyperparameter tuning, it's wise to use cross-validation to ensure the model doesn't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ee1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#placing neighbors and corresponding accuracy in a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'neighbors':neighbors_list,\n",
    "    'accuracy':accuracy_list\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting Learning Curves\n",
    "plt.plot(results_df['neighbors'],\n",
    "        results_df['accuracy'])\n",
    "\n",
    "#adding the labels and title\n",
    "plt.gca().set(xlabel='n_neighbors', ylabel='Accuracy',\n",
    "             title='Accuracy for different n_neighbors')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rates & results storage\n",
    "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "results_list = []\n",
    "\n",
    "# Create the for loop to evaluate model predictions for each learning rate\n",
    "for learning_rate in learning_rates:\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate)\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    # Save the learning rate and accuracy score\n",
    "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])\n",
    "\n",
    "# Gather everything into a DataFrame\n",
    "results_df = pd.DataFrame(results_list, columns=['learning_rate', \n",
    "                                                 'accuracy'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d19183",
   "metadata": {},
   "source": [
    "##### Some hyperparameters are not important for model performance\n",
    "- These are more for computational reasons/decisions\n",
    "\n",
    "For Random Classifier, these will not assist in model performance:\n",
    "- n_jobs\n",
    "- random_state\n",
    "- verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the old estimator, notice which hyperparameter is badly set\n",
    "print(rf_clf_old)\n",
    "\n",
    "# Get confusion matrix & accuracy for the old rf_model\n",
    "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
    "  \tconfusion_matrix(y_test, rf_old_predictions),  \n",
    "  \taccuracy_score(y_test, rf_old_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbf532",
   "metadata": {},
   "source": [
    "Additional things to consider:\n",
    "- which hyperparameters *might conflict*\n",
    "- reasoning out if the values on the hyperparameters makes sense (such as low number of trees in a decision model or having 1 Neighbor as a robust KNN model?)\n",
    "- incrementing a hyperparameter by a very small amount will unlikely improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eef7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation function\n",
    "\n",
    "def gbm_grid_search(learn_rate, max_depth):\n",
    "    model = GradientBoostingClassifier(\n",
    "    learning_rate = learn_rate,\n",
    "    max_depth = max_depth)\n",
    "    predictions = mode.fit(X_train, y_train).predict(X_test)\n",
    "    return ([learn_rate, max_depth, accuracy_score(y_test, predictions)])\n",
    "\n",
    "#look through the list of hyperparamters and call function\n",
    "return_list = []\n",
    "\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate, max_depth))\n",
    "        \n",
    "#save results in DataFrame to view\n",
    "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'max_depth', 'accuracy'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c17774",
   "metadata": {},
   "source": [
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d3b7c",
   "metadata": {},
   "source": [
    "Advantages of GridSearch:\n",
    "- You don't have to write thousands of lines of code\n",
    "\n",
    "Steps in a Grid Search:\n",
    "- An algorithm to tune the hyperparameters (ie. an estimator)\n",
    "- Defining which hyperparameters we will tune\n",
    "- Defining a range of values for each hyperparameter\n",
    "- Setting a cross-validation scheme\n",
    "- Define a score function so we can decide which square on our grid was 'the best'\n",
    "- Include extra useful information or functions\n",
    "\n",
    "GridSearchCV Object Inputs\n",
    "- **estimator**\n",
    "- **param_grid** - requires a dictionary with parameter names and values\n",
    "    - and the keys must be valid hyperparameters\n",
    "- **cv**\n",
    "- **scoring**\n",
    "- **refit**\n",
    "- **n_jobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all available metrics using:\n",
    "from sklearn import metrics\n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#specify the hyperparameter\n",
    "param_grid = {'n_neighbors' : np.arange(1, 50)}\n",
    "\n",
    "#instantiate classifier (this scenario KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#use gridsearchcv and param_grid defined above\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "#performing the fit for the searchgrid in place\n",
    "knn_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a16658",
   "metadata": {},
   "source": [
    "##### GridSearchCV Output Properties:\n",
    "- 1 - Result Log : **cv_results_**\n",
    "- 2 - Best results:\n",
    "    - **best_index_**\n",
    "    - **best_params_**\n",
    "    - **best_score_**\n",
    "- 3 - Extra information\n",
    "    - **scorer_**\n",
    "    - **n_splits_**\n",
    "    - **refit_time_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08abfff",
   "metadata": {},
   "source": [
    "#### Retrieve the hyperparameters that performed the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09852bcb",
   "metadata": {},
   "source": [
    "The optimal hyperparameters are those of the model achieving the best CV score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6193818",
   "metadata": {},
   "source": [
    "#### RandomizedCV Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ea6e7",
   "metadata": {},
   "source": [
    "How Random Search is similar to grid search:\n",
    "- Define an estimator, which hyperparamters to tune and the range of values for each hyperparameter\n",
    "- still set a cross-validation scheme and scoring function\n",
    "- BUT instead, randomly select grid squares\n",
    "\n",
    "This works because:\n",
    "- Not every hyperparameter is as important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#parameters and distributions\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821d4d3",
   "metadata": {},
   "source": [
    "#### Another example with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "params_dt = {\n",
    "    'max_depth':[3,4,5,6],\n",
    "    'min_samples_leaf':[0.04,0.06,0.08],\n",
    "    'max_features':[0.2,0.4,0.6,0.8]\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                      param_grid = params_dt,\n",
    "                      scoring='accuracy',\n",
    "                      cv=10,\n",
    "                      n_jobs=1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "#extracting best parameters from grid_dt after training\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)\n",
    "\n",
    "#extract best CV score from 'grid_dt'\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy'.format(best_CV_score))\n",
    "\n",
    "#extract best model from grid_dt\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "#evaluate test set accuracy\n",
    "test_acc = best_model.score(X_test, y_test)\n",
    "print(\"Test set accuracy of best model: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb6b52",
   "metadata": {},
   "source": [
    "### Inspecting Random Forest Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "SEED=1\n",
    "rf = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "#inspecting rf's hyperparameters\n",
    "rf.get_params()\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#dictionary of parameters\n",
    "params_rf = {\n",
    "    'n_estimators': [300,400,500],\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_samples_leaf':[0.1,0.2],\n",
    "    'max_features':['log2','sqrt']\n",
    "}\n",
    "\n",
    "#instantiate GriSearchCV object\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                      param_grid=params_rf,\n",
    "                      cv=3,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      verbose=1,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "best_hyperparams = grid_rf.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)\n",
    "\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
